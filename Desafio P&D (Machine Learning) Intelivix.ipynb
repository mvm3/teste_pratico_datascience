{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relatório Desafio P&D (Machine Learning) Intelivix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aplicante: Mitterrand Vieira Monteiro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introdução"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste relatório estão expressas as etapas para resolver o desafio proposto. Os tópicos iniciais deste relatório apresentam as tentativas para a resolução do problema e no final é mostrado o código."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preparação dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após carregada a base de dados, foi verificado se havia algum valor nulo ou incoerente no dados. Felizmente, todos os valores estavam de acordo e essa checagem se fez desnecessária.\n",
    "Foi decidido, também, remover as colunas de Identificação (Id e IdSentença) visto que estas não seriam utilizadas nos algoritmos de classificação."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count Vectorize foi escolhida como Feature Engineering por apresentar menor complexidade de código."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Algoritmos de Classificação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Três Algoritmos de Classificação foram escolhidos: Naive Bayes, Linear Classifier e Random Forest. As escolhas partiram da minha zona de conforto e da tentativa de mesclar algoritmos com diferentes niveis de dificuldade de implementação."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Código Desafio P&D (Machine Learning) Intelivix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas, numpy, string\n",
    "from sklearn import metrics, model_selection, preprocessing, naive_bayes, linear_model, ensemble\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#funcao que determina a proximidade entre o valor obtido pelo algoritmo(previsao) e o valor verdadeiro\n",
    "def acuracia(algoritmo, vetor_treino, classe, vetor_validacao):\n",
    "    algoritmo.fit(vetor_treino, classe)\n",
    "    previsao = algoritmo.predict(vetor_validacao)\n",
    "    return metrics.accuracy_score(previsao, valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#carrega os dados\n",
    "dados = pandas.read_csv(\"C:/Users/Casa/Desktop/dados/train.tsv\", sep='\\t')\n",
    "\n",
    "#exclui colunas desnecessarias para o algoritmo de classificacao\n",
    "dados.drop([\"Id\"], 1, inplace=True)\n",
    "dados.drop([\"IdSentenca\"], 1, inplace=True)\n",
    "\n",
    "#preparacao dos dados de treino e validacao\n",
    "train_X, valid_X, train_y, valid_y = model_selection.train_test_split(dados['Texto'], dados['Sentimento'])\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "train_y = encoder.fit_transform(train_y)\n",
    "valid_y = encoder.fit_transform(valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Usando Count Vectorize como a Feature Engineering\n",
    "aux = CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}')\n",
    "aux.fit(dados['Texto'])\n",
    "X_train_count = aux.transform(train_X)\n",
    "X_valid_count = aux.transform(valid_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuracia Naive Bayes:  0.6076893502499039\n"
     ]
    }
   ],
   "source": [
    "#Naive Bayes\n",
    "print (\"Acuracia Naive Bayes: \", acuracia(naive_bayes.MultinomialNB(), X_train_count, train_y, X_valid_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuracia Linear Classifier:  0.6499807766243753\n"
     ]
    }
   ],
   "source": [
    "#Linear Classifier\n",
    "print (\"Acuracia Linear Classifier: \", acuracia(linear_model.LogisticRegression(solver='newton-cg', max_iter=100, multi_class='auto'), X_train_count, train_y, X_valid_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuracia Random Forest:  0.6196591054722542\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "print (\"Acuracia Random Forest: \", acuracia(ensemble.RandomForestClassifier(n_estimators=10, random_state=0), X_train_count, train_y, X_valid_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo de execucao Naive Bayes:\n",
      "61.8 ms ± 889 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "print(\"Tempo de execucao Naive Bayes:\")\n",
    "%timeit acuracia(naive_bayes.MultinomialNB(), X_train_count, train_y, X_valid_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo de execucao Linear Classifier:\n",
      "58.1 s ± 1.68 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "print(\"Tempo de execucao Linear Classifier:\")\n",
    "%timeit acuracia(linear_model.LogisticRegression(solver='newton-cg', max_iter=100, multi_class='auto'), X_train_count, train_y, X_valid_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo de execucao Random Forest:\n",
      "2min 58s ± 15.7 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "print(\"Tempo de execucao Random Forest:\")\n",
    "%timeit acuracia(ensemble.RandomForestClassifier(n_estimators=10, random_state=0), X_train_count, train_y, X_valid_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Conclusão"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O melhor algoritmo para a solução do problema apresentado seria o Linear Classifier.\n",
    "Linear Classifier obteve a maior acurácia entre os três algoritmos de classificação e o segundo menor tempo de computação."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
